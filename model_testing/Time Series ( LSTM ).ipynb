{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_hrs = 1\n",
    "shift_steps = shift_hrs*2\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Data/solar_original.csv')\n",
    "data['TimeStamp']=pd.to_datetime(data.Date+' '+data.Time,infer_datetime_format=True)\n",
    "data['DayOfYear']=pd.to_datetime(data.Date,dayfirst=True).dt.dayofyear\n",
    "data=data.drop(['Date','Time','TimeStamp'],axis=1)\n",
    "#X = data.iloc[:,1:]\n",
    "#Y=data['solar_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solar_output</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>visibility</th>\n",
       "      <th>serial</th>\n",
       "      <th>DayOfYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14216</td>\n",
       "      <td>27.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.34680</td>\n",
       "      <td>27.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.37716</td>\n",
       "      <td>28.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.67044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   solar_output  temperature  humidity  wind_speed  visibility  serial  \\\n",
       "0       0.00000         27.0      74.0         0.0         4.0       1   \n",
       "1       0.14216         27.0      74.0         1.9         4.0       2   \n",
       "2       1.34680         27.0      74.0         0.0         4.0       3   \n",
       "3       3.37716         28.0      70.0         7.4         4.0       4   \n",
       "4       5.67044         28.0      70.0         9.3         4.0       5   \n",
       "\n",
       "   DayOfYear  \n",
       "0        275  \n",
       "1        275  \n",
       "2        275  \n",
       "3        275  \n",
       "4        275  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['solar_output'].shift(-shift_steps)\n",
    "X=data.drop(['solar_output'],axis=1)\n",
    "\n",
    "x_data = X.values[0:-shift_steps]\n",
    "y_data = Y.values[0:-shift_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 27.  ,  74.  ,   0.  ,   4.  ,   1.  , 275.  ],\n",
       "        [ 27.  ,  74.  ,   1.9 ,   4.  ,   2.  , 275.  ],\n",
       "        [ 27.  ,  74.  ,   0.  ,   4.  ,   3.  , 275.  ],\n",
       "        ...,\n",
       "        [ 40.  ,   6.  ,  13.  ,   6.  ,  21.  ,  89.  ],\n",
       "        [ 40.  ,   6.  ,  11.79,   6.  ,  22.  ,  89.  ],\n",
       "        [ 40.  ,   6.  ,  11.1 ,   6.  ,  23.  ,  89.  ]]),\n",
       " array([1.3468 , 3.37716, 5.67044, ..., 7.60269, 4.1613 , 1.59809]))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4498,) (4498, 6)\n"
     ]
    }
   ],
   "source": [
    "print (y_data.shape,x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "x_data_scaled=x_scaler.fit_transform(x_data)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_data_scaled=y_scaler.fit_transform(y_data.reshape(-1, 1)).ravel()\n",
    "\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(x_data_scaled, y_data_scaled, test_size=0.3,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_generator(batch_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        x_shape = (batch_size, sequence_length, 6)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        y_shape = (batch_size, sequence_length, 1)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n",
    "            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n",
    "        \n",
    "        yield (x_batch, y_batch)\n",
    "\n",
    "sequence_length=10*24*7 # Days * Iteams per day * No of Days\n",
    "generator = batch_generator(batch_size=256,\n",
    "                    sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(x_test_scaled, axis=0),\n",
    "                   np.expand_dims(y_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [rows, timesteps, columns]\n",
    "x_train_scaled=x_train_scaled.reshape(x_train_scaled.shape[0],1,x_train_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "n_batch=1\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(10, batch_input_shape=(n_batch, x_train_scaled.shape[1], x_train_scaled.shape[2]), stateful=True))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 36s 11ms/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0614\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0416\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0287\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0228\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0202\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0190\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0182\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0176\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0171\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0167\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0164\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0161\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0159\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0157\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0155\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0153\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 18s 6ms/step - loss: 0.0151\n",
      "Epoch 1/1\n",
      "2138/3148 [===================>..........] - ETA: 5s - loss: 0.0146"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "n_epoch=100\n",
    "for i in range(n_epoch):\n",
    "    model.fit(x_train_scaled, y_train_scaled, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
    "    model.reset_states()\n",
    "# batch forecast\n",
    "yhat = model.predict(X, batch_size=n_batch)\n",
    "for i in range(len(y)):\n",
    "    print('>Expected=%.1f, Predicted=%.1f' % (y[i], yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
